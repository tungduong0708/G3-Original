{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13be68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Collecting torch==2.7.0\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torch-2.7.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision==0.22.0\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchvision-0.22.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.7.0\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.7.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.7.0) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.7.0) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.7.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.7.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.7.0) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/cu126/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch==2.7.0)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision==0.22.0) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision==0.22.0) (10.2.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.3.0->torch==2.7.0) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch==2.7.0) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu126/torch-2.7.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (867.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.0/867.0 MB\u001b[0m \u001b[31m213.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchvision-0.22.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/torchaudio-2.7.0%2Bcu126-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m275.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m274.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m292.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m247.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m197.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m192.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m193.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m202.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m179.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m282.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu126/nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading https://download.pytorch.org/whl/triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m290.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.1\n",
      "    Uninstalling sympy-1.13.1:\n",
      "      Successfully uninstalled sympy-1.13.1\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "Successfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.13.3 torch-2.7.0+cu126 torchaudio-2.7.0+cu126 torchvision-0.22.0+cu126 triton-3.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.52.3)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.31.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.7.0+cu126)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (72.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.7.0 torchvision==0.22.0 torchaudio==2.7.0 --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install transformers accelerate huggingface_hub pandas optuna pyproj einops geopy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1acad77-8612-43fd-a8e6-31af4daf8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 23 08:01:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  |   00000000:C1:00.0 Off |                  N/A |\n",
      "|  0%   57C    P8             19W /  350W |       0MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7205752a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  425k  100  425k    0     0   813k      0 --:--:-- --:--:-- --:--:--  813k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o data/im2gps3k/im2gps3k_places365.csv \\\n",
    "     https://raw.githubusercontent.com/TIBHannover/GeoEstimation/original_tf/meta/im2gps3k_places365.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf0f5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1cf27f3cf84ebaa681a7107c4fc73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MP16_Pro_filtered.csv:   0%|          | 0.00/747M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata/MP16_Pro_filtered.csv to /data/mp16/metadata/MP16_Pro_filtered.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3553766a8ab34b79b9a85c5823dea655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MP16_Pro_places365.csv:   0%|          | 0.00/859M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata/MP16_Pro_places365.csv to /data/mp16/metadata/MP16_Pro_places365.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13406647010d43cfabad14ddfddcc8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mp16_urls.csv:   0%|          | 0.00/385M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded metadata/mp16_urls.csv to /data/mp16/metadata/mp16_urls.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9641dc1576704ed7b1f22c5bf76f664b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mp-16-images00:   0%|          | 0.00/21.5G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded mp-16-images00 to /data/mp16/mp-16-images00\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download, login\n",
    "\n",
    "login(token=\"API_KEY\")\n",
    "\n",
    "\n",
    "# Specify the repository\n",
    "repo_id = \"Jia-py/MP16-Pro\"\n",
    "\n",
    "# List of files to download\n",
    "files = [\n",
    "    \"metadata/MP16_Pro_filtered.csv\",\n",
    "    \"metadata/MP16_Pro_places365.csv\",\n",
    "    \"metadata/mp16_urls.csv\",\n",
    "    \"mp-16-images00\"\n",
    "]\n",
    "\n",
    "# Download each file\n",
    "for file in files:\n",
    "    try:\n",
    "        file_path = hf_hub_download(repo_id=repo_id, filename=file, repo_type=\"dataset\", local_dir=\"/data/mp16/\")\n",
    "        print(f\"Downloaded {file} to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {file}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5bdea04-15b3-4fba-bbf3-2bee63c588fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /data/mp16/metadata/*.csv /data/mp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e5b444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Unexpected EOF in archive\n",
      "tar: Unexpected EOF in archive\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!tar -xf /data/mp16/mp-16-images00 -C /data/mp16/\n",
    "\n",
    "!cd /data/mp16/images && \\\n",
    " ls > /data/mp16/all_files.txt && \\\n",
    " total=$(wc -l < /data/mp16/all_files.txt) && \\\n",
    " part=$((total / 10)) && \\\n",
    " head -n \"$part\" /data/mp16/all_files.txt > /data/mp16/part_files.txt && \\\n",
    " tar -cf /data/mp16/mp-16-images.tar -T /data/mp16/part_files.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab080eb-9055-4d48-bf9f-f22e33e6d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_files.txt  metadata\t\t mp-16-images00\n",
      "images\t       mp-16-images.tar  part_files.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /data/mp16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-05-23 08:14:30,620]\u001b[0m Using an existing study with name 'mp16-sh-siren' instead of creating a new one.\u001b[0m\n",
      "read text data success\n",
      "no exist tar index success, need building...\n",
      "25642it [00:00, 29226.87it/s]\n",
      "tar index buidling success\n",
      "data columns:  22396\n",
      "location from str to float success\n",
      "logit_scale1 torch.Size([])\n",
      "logit_scale2 torch.Size([])\n",
      "logit_scale3 torch.Size([])\n",
      "location_encoder.LocEnc0.capsule.1.weight torch.Size([1024, 512])\n",
      "location_encoder.LocEnc0.capsule.1.bias torch.Size([1024])\n",
      "location_encoder.LocEnc0.capsule.3.weight torch.Size([1024, 1024])\n",
      "location_encoder.LocEnc0.capsule.3.bias torch.Size([1024])\n",
      "location_encoder.LocEnc0.capsule.5.weight torch.Size([1024, 1024])\n",
      "location_encoder.LocEnc0.capsule.5.bias torch.Size([1024])\n",
      "location_encoder.LocEnc0.head.0.weight torch.Size([512, 1024])\n",
      "location_encoder.LocEnc0.head.0.bias torch.Size([512])\n",
      "location_encoder.LocEnc1.capsule.1.weight torch.Size([1024, 512])\n",
      "location_encoder.LocEnc1.capsule.1.bias torch.Size([1024])\n",
      "location_encoder.LocEnc1.capsule.3.weight torch.Size([1024, 1024])\n",
      "location_encoder.LocEnc1.capsule.3.bias torch.Size([1024])\n",
      "location_encoder.LocEnc1.capsule.5.weight torch.Size([1024, 1024])\n",
      "location_encoder.LocEnc1.capsule.5.bias torch.Size([1024])\n",
      "location_encoder.LocEnc1.head.0.weight torch.Size([512, 1024])\n",
      "location_encoder.LocEnc1.head.0.bias torch.Size([512])\n",
      "location_encoder.LocEnc2.capsule.1.weight torch.Size([1024, 512])\n",
      "location_encoder.LocEnc2.capsule.1.bias torch.Size([1024])\n",
      "location_encoder.LocEnc2.capsule.3.weight torch.Size([1024, 1024])\n",
      "location_encoder.LocEnc2.capsule.3.bias torch.Size([1024])\n",
      "location_encoder.LocEnc2.capsule.5.weight torch.Size([1024, 1024])\n",
      "location_encoder.LocEnc2.capsule.5.bias torch.Size([1024])\n",
      "location_encoder.LocEnc2.head.0.weight torch.Size([512, 1024])\n",
      "location_encoder.LocEnc2.head.0.bias torch.Size([512])\n",
      "vision_projection_else_1.0.weight torch.Size([768, 768])\n",
      "vision_projection_else_1.0.bias torch.Size([768])\n",
      "vision_projection_else_1.2.weight torch.Size([768, 768])\n",
      "vision_projection_else_1.2.bias torch.Size([768])\n",
      "text_projection_else.0.weight torch.Size([768, 768])\n",
      "text_projection_else.0.bias torch.Size([768])\n",
      "text_projection_else.2.weight torch.Size([768, 768])\n",
      "text_projection_else.2.bias torch.Size([768])\n",
      "vision_projection_else_2.0.weight torch.Size([768, 768])\n",
      "vision_projection_else_2.0.bias torch.Size([768])\n",
      "vision_projection_else_2.2.weight torch.Size([768, 768])\n",
      "vision_projection_else_2.2.bias torch.Size([768])\n",
      "location_projection_else.0.weight torch.Size([512, 512])\n",
      "location_projection_else.0.bias torch.Size([512])\n",
      "location_projection_else.2.weight torch.Size([768, 512])\n",
      "location_projection_else.2.bias torch.Size([768])\n",
      "step 0/88, loss 11.9399, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7758.00 MB\n",
      "step 1/88, loss 11.8205, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 2/88, loss 11.5297, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 3/88, loss 11.4056, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 4/88, loss 11.4084, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 5/88, loss 11.3605, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 6/88, loss 11.2638, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 7/88, loss 11.0443, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 8/88, loss 10.9838, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 9/88, loss 10.9131, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 10/88, loss 10.7885, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 11/88, loss 10.8058, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 12/88, loss 10.6961, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 13/88, loss 10.6498, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 14/88, loss 10.4981, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 15/88, loss 10.4879, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 16/88, loss 10.4133, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 17/88, loss 10.3414, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 18/88, loss 10.3875, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 19/88, loss 10.3005, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 20/88, loss 10.2333, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 21/88, loss 10.1041, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 22/88, loss 10.2055, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 23/88, loss 9.9916, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 24/88, loss 9.9504, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 25/88, loss 9.8551, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 26/88, loss 9.8882, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 27/88, loss 9.8008, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 28/88, loss 9.8480, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 29/88, loss 9.4931, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 30/88, loss 9.6893, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 31/88, loss 9.6116, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 32/88, loss 9.4743, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 33/88, loss 9.4595, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 34/88, loss 9.4976, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 35/88, loss 9.2739, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 36/88, loss 9.2462, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 37/88, loss 9.5081, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 38/88, loss 9.2782, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 39/88, loss 9.1062, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 40/88, loss 9.2566, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 41/88, loss 9.1358, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 42/88, loss 8.9966, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 43/88, loss 9.0133, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 44/88, loss 8.9209, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 45/88, loss 8.9955, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 46/88, loss 8.8167, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 47/88, loss 8.6424, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 48/88, loss 9.0667, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 49/88, loss 8.7955, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 50/88, loss 8.8569, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 51/88, loss 8.8078, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 52/88, loss 8.8863, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 53/88, loss 8.9049, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 54/88, loss 8.6248, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 55/88, loss 8.4564, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 56/88, loss 8.4680, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 57/88, loss 8.7680, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 58/88, loss 8.6363, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 59/88, loss 8.6557, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 60/88, loss 8.5846, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 61/88, loss 8.2768, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 62/88, loss 8.6666, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 63/88, loss 8.5120, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 64/88, loss 8.4207, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 65/88, loss 8.0560, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 66/88, loss 8.5453, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 67/88, loss 8.5063, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 68/88, loss 8.3492, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 69/88, loss 8.3510, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 70/88, loss 8.1732, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 71/88, loss 8.1906, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 72/88, loss 8.1814, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 73/88, loss 8.1696, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 74/88, loss 8.2208, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 75/88, loss 8.4182, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 76/88, loss 8.0274, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 77/88, loss 8.3188, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 78/88, loss 8.0267, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 79/88, loss 8.0262, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 80/88, loss 8.0395, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 81/88, loss 7.9734, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 82/88, loss 7.9941, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 83/88, loss 8.2151, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 84/88, loss 7.6915, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 85/88, loss 7.9252, lr 0.000030, VRAM allocated: 2010.38 MB, reserved: 7760.00 MB\n",
      "step 86/88, loss 8.2504, lr 0.000030, VRAM allocated: 2011.38 MB, reserved: 7760.00 MB\n",
      "step 87/88, loss 6.7891, lr 0.000030, VRAM allocated: 1932.37 MB, reserved: 7760.00 MB\n",
      "step 0/88, loss 7.6262, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 1/88, loss 7.5302, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 2/88, loss 7.8609, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 3/88, loss 7.8062, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 4/88, loss 7.4338, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 5/88, loss 7.9659, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 6/88, loss 7.8357, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 7/88, loss 7.6513, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 8/88, loss 7.5462, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 9/88, loss 7.9233, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 10/88, loss 7.5665, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 11/88, loss 7.6667, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 12/88, loss 7.9068, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 13/88, loss 7.3964, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 14/88, loss 7.3166, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 15/88, loss 7.5877, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 21/88, loss 7.6861, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 22/88, loss 7.8119, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 23/88, loss 7.5921, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 24/88, loss 7.4121, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 25/88, loss 7.2765, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 26/88, loss 7.5853, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 27/88, loss 7.6172, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 28/88, loss 7.6874, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 29/88, loss 7.0385, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 30/88, loss 7.4894, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 31/88, loss 7.3178, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 32/88, loss 7.2228, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 33/88, loss 7.2129, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 34/88, loss 7.4292, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 35/88, loss 7.2824, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 36/88, loss 7.0670, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 37/88, loss 7.6689, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 38/88, loss 7.3677, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 39/88, loss 7.2222, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 40/88, loss 7.5021, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n",
      "step 41/88, loss 7.3364, lr 0.000026, VRAM allocated: 2010.38 MB, reserved: 7762.00 MB\n",
      "step 42/88, loss 6.9742, lr 0.000026, VRAM allocated: 2011.38 MB, reserved: 7762.00 MB\n"
     ]
    }
   ],
   "source": [
    "!python tune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f640-56ac-4816-9c7e-f9c861f50e27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
